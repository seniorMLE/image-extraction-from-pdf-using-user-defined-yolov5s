{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "import onnx\n",
        "from onnx_tf.backend import prepare\n",
        "import os\n",
        "import subprocess\n",
        "import tensorflow as tf\n",
        "from pdf2image import convert_from_path, convert_from_bytes\n",
        "from tkinter import filedialog as fd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pdf2image.exceptions import (\n",
        "    PDFInfoNotInstalledError,\n",
        "    PDFPageCountError,\n",
        "    PDFSyntaxError\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5  v6.0-266-g07221f1 torch 1.10.2+cpu CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "weight_path = fd.askopenfilename()\n",
        "model = torch.hub.load('yolov5', 'custom', path=weight_path, source='local')\n",
        "# !python yolov5/export.py --weights yolob5s.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: modelTF\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Assets written to: modelTF\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        }
      ],
      "source": [
        "model_onnx = onnx.load('yolov5s.onnx')\n",
        "tf_rep = prepare(model_onnx)\n",
        "tf_rep.export_graph('modelTF')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "pb_modle = tf.saved_model.load(r'modelTF')\n",
        "f = pb_modle.signatures[\"serving_default\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "filepath = fd.askopenfilename()\n",
        "filename_and_ext = os.path.basename(filepath).split('.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "threshold = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images = convert_from_path(filepath, dpi=95)\n",
        "results = []\n",
        "for i in range(len(images)):\n",
        "    k = 1    \n",
        "    saved_filename = filename_and_ext[0] + '_' + str(i+1)\n",
        "    images[i].save( saved_filename + '.png', 'PNG')\n",
        "\n",
        "    \n",
        "    result_deteced_from_image = model(saved_filename + '.png')\n",
        "    # result_deteced_from_image.save(saved_filename+'_from model' + '.png')\n",
        "    results.append(result_deteced_from_image)\n",
        "    data_detected = results[i].pandas().xyxy[0]    \n",
        "    print(data_detected)\n",
        "    num_object = data_detected.shape[0]\n",
        "    for j in range(num_object):\n",
        "        if data_detected['confidence'][j] > threshold:\n",
        "            imc = images[i].crop((data_detected['xmin'][j], data_detected['ymin'][j], data_detected['xmax'][j], data_detected['ymax'][j]))    \n",
        "            image_name = str(data_detected['confidence'][j]) + '_' + str(k) + '_' + filename_and_ext[0] + '_' + str(i+1)            \n",
        "            imc.save(image_name+'.png')\n",
        "            k += 1    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(808, 1045)"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from PIL import Image\n",
        "img = Image.open('test_2.png')\n",
        "img = img.convert('RGB')\n",
        "img.size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "test_image = load_img('test_2.png', target_size=(640,640))\n",
        "# print(test_image)\n",
        "image =  img_to_array(test_image)/255.0\n",
        "image = np.transpose(image)\n",
        "\n",
        "# print(image)\n",
        "import numpy as np\n",
        "image = np.expand_dims(image, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 3, 640, 640)"
            ]
          },
          "execution_count": 205,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [],
      "source": [
        "converted_imgage = tf.image.convert_image_dtype(img, dtype='float')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tt = tf.expand_dims(converted_imgage, axis=0)\n",
        "tt = converted_imgage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1045, 808, 3)\n"
          ]
        }
      ],
      "source": [
        "print(tt.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'output': TensorShape([1, 25200, 85]),\n",
              " '339': TensorShape([1, 3, 80, 80, 85]),\n",
              " '443': TensorShape([1, 3, 20, 20, 85]),\n",
              " '391': TensorShape([1, 3, 40, 40, 85])}"
            ]
          },
          "execution_count": 217,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pb_modle = tf.saved_model.load(r'modelTF')\n",
        "f = pb_modle.signatures[\"serving_default\"]\n",
        "f.output_shapes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 3, 640, 640)\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 25200, 85), dtype=float32, numpy=\n",
              "array([[[     4.9628,      2.0368,       9.751, ...,   0.0022384,   0.0020137,    0.031211],\n",
              "        [     11.478,      2.3212,      20.426, ...,    0.002461,   0.0022058,     0.02976],\n",
              "        [     18.209,      2.1291,      26.646, ...,   0.0021883,   0.0025875,    0.045289],\n",
              "        ...,\n",
              "        [      565.8,      606.15,      156.95, ...,   0.0058575,   0.0023872,    0.013404],\n",
              "        [     586.22,      607.89,      123.86, ...,   0.0084011,   0.0026894,    0.021166],\n",
              "        [     621.59,      618.72,       130.1, ...,   0.0076936,   0.0026491,    0.014792]]], dtype=float32)>"
            ]
          },
          "execution_count": 216,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(image.shape)\n",
        "print(type(image))\n",
        "image = tf.convert_to_tensor(image, dtype='float')\n",
        "outputs = f(image)\n",
        "outputs['output']\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Tacotron Synthesis Notebook.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
